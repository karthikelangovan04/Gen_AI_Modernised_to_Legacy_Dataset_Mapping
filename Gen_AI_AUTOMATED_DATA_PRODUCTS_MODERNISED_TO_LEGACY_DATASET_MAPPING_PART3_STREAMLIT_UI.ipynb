{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150ede34-08fc-4930-a4b1-09cc76226df4",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "This code creates a Streamlit web application for comparing and mapping data between modernized and legacy tables in Snowflake. It uses AI models to analyze the data and generate mappings, with options for incorporating vector embeddings and sample data. The app allows users to input table information, select AI models and parameters, and view the generated prompts and AI responses.\n\n# Import necessary libraries\nimport streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nimport json\n\n# Get the current Snowflake session\nsession = get_active_session()\n\n# Set up the Streamlit app title\nst.title(\"Data Comparison and Mapping Tool\")\n\n# Initialize session state variables for storing prompt, AI response, and token count\n# These persist across reruns of the app\n\n# Input fields for user to enter database, schema, and table information\n# Default values are provided for convenience\n\n# Dropdown for selecting the AI model to use\n\n# Checkboxes for additional options (vector embeddings and sample data)\n\n# Function to fetch available vector embeddings based on table names\ndef fetch_available_embeddings(modern_table, legacy_table):\n    # Query Snowflake to get relevant vector mappings\n\n# Fetch and display available embeddings if any are found\n\n# Function to generate the prompt for the AI model\ndef generate_prompt():\n    # Construct the prompt based on user selections and data\n    # Include vector embeddings and/or sample data if selected\n    # Format the prompt with instructions for the AI model\n\n# Function to get the AI response using Snowflake's CORTEX.COMPLETE function\ndef get_ai_response(options):\n    # Call the AI model with the generated prompt and user-specified parameters\n    # Handle the response and any potential errors\n\n# Button to generate the prompt\n# When clicked, it generates the prompt and calculates the token count\n\n# Display the generated prompt and token count if available\n\n# UI for setting AI model parameters (temperature, max tokens, top p)\n\n# Button to get the AI response\n# When clicked, it calls the AI model with the generated prompt and chosen parameters\n\n# Display the AI model response, including the generated text and usage statistics"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "import streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nimport json\n\n# Get the current Snowflake session\nsession = get_active_session()\n\nst.title(\"Data Comparison and Mapping Tool\")\n\n# Initialize session state variables\nif 'prompt' not in st.session_state:\n    st.session_state.prompt = \"\"\nif 'ai_response' not in st.session_state:\n    st.session_state.ai_response = \"\"\nif 'token_count' not in st.session_state:\n    st.session_state.token_count = 0\n\n# Input fields for database, schema, and table names\ndatabase_name = st.text_input(\"Enter Database Name\", \"DATA_OPS_MAPPING\")\nschema_name = st.text_input(\"Enter Schema Name\", \"DATA_ONESTREAM\")\nmodern_table_name = st.text_input(\"Enter Modernised Table Name\", \"Deposit_Accounts_Onestream\")\nlegacy_table_name = st.text_input(\"Enter Legacy Table Name\", \"LEGACY_DEPOSIT_ACCOUNTS\")\nrecord_limit = st.number_input(\"Enter Sample Record Limit\", min_value=1, value=5)\n\n# Model selection\nmodel = st.selectbox(\"Select AI Model\", [\n    \"snowflake-arctic\", \"mistral-large\", \"reka-flash\", \"reka-core\", \"mixtral-8x7b\",\n    \"jamba-instruct\", \"llama2-70b-chat\", \"llama3-8b\", \"llama3-70b\", \"llama3.1-8b\",\n    \"llama3.1-70b\", \"llama3.1-405b\", \"mistral-7b\", \"gemma-7b\"\n])\n\n# Options for prompt generation\nuse_vector_embeddings = st.checkbox(\"Use Vector Embeddings\")\nuse_sample_data = st.checkbox(\"Use Sample Data\")\n\ndef fetch_available_embeddings(modern_table, legacy_table):\n    query = f\"\"\"\n    SELECT VECTOR_MAPPING_FOR_TABLE_NAME \n    FROM SMART_AI_MAPPER.SMART_AI_MAPPER_TOOL.TOP_3_SIMILAR_FIELDS_FROM_VEC_EMB\n    WHERE UPPER(VECTOR_MAPPING_FOR_TABLE_NAME) LIKE '%{modern_table.upper()}%' \n    AND UPPER(VECTOR_MAPPING_FOR_TABLE_NAME) LIKE '%{legacy_table.upper()}%'\n    GROUP BY 1\n    \"\"\"\n    result = session.sql(query).collect()\n    return [row['VECTOR_MAPPING_FOR_TABLE_NAME'] for row in result]\n\n# Fetch available embeddings\navailable_embeddings = fetch_available_embeddings(modern_table_name, legacy_table_name)\n\n# Dropdown for selecting embedding\nselected_embedding = None\nif available_embeddings:\n    selected_embedding = st.selectbox(\"Select Vector Embedding\", available_embeddings)\nelse:\n    st.warning(\"No matching vector embeddings found for the given table names.\")\n\ndef generate_prompt():\n    combined_data = {}\n    prompt_text = \"Given the provided data, compare the fields between the Modernised and Legacy tables. \"\n    \n    if use_vector_embeddings and selected_embedding:\n        # Fetch vector embeddings and mappings\n        vector_mappings = session.sql(f\"\"\"\n        SELECT ARRAY_AGG(\n            OBJECT_CONSTRUCT(*)) AS JSON_DATA FROM\n            (\n        SELECT VECTOR_MAPPING_FOR_TABLE_NAME,        \n         LISTAGG(CONCAT(MODERNISED_TABLE_FIELD_NAME,'-',TOP_SIMILARITIES_LEGACY_FIELDS,',')) within group \n            (ORDER BY MODERNISED_TABLE_FIELD_NAME ) AS Modern_table_field_to_legacy_table_mappings\n        FROM  SMART_AI_MAPPER.SMART_AI_MAPPER_TOOL.TOP_3_SIMILAR_FIELDS_FROM_VEC_EMB\n        WHERE VECTOR_MAPPING_FOR_TABLE_NAME = '{selected_embedding}'\n        GROUP BY 1)\n        \"\"\").collect()[0]['JSON_DATA']\n        combined_data[\"vector_mappings\"] = vector_mappings\n        prompt_text += \"Use the vector embeddings to help map fields between the Modernised table and the Legacy table. \"\n    \n    if use_sample_data:\n        # Call the stored procedure for modern table\n        modern_result = session.call('fetch_and_process_table_data', \n                                     database_name, \n                                     schema_name, \n                                     modern_table_name, \n                                     record_limit)\n        \n        # Call the stored procedure for legacy table\n        legacy_result = session.call('fetch_and_process_table_data', \n                                     database_name, \n                                     schema_name, \n                                     legacy_table_name, \n                                     record_limit)\n        \n        combined_data[\"modern_data\"] = modern_result\n        combined_data[\"legacy_data\"] = legacy_result\n        prompt_text += \"Analyze the sample data to identify discrepancies and provide a mapping between the two tables. Highlight any differences in field names or data values. \"\n    \n    prompt_text += \"\"\"\n    For fields with mismatches, suggest corrections and as per mapping identified, provide a Snowflake compatiable SQL query to transform data from Modernised table to align with the Legacy Table. \n    Ensure that all data matches correctly between Modernised and Legacy, Report if any discrepancies and apply if transformations required in the snowflake \n    SQL generated.\n    If there are fields in one table that do not have direct matches in the other table, note these discrepancies and indicate how to handle them.\n    \n    Data: {data}\n    \"\"\"\n    \n    st.session_state.prompt = prompt_text.format(data=json.dumps(combined_data))\n\ndef get_ai_response(options):\n    try:\n        # Call the CORTEX.COMPLETE function directly\n        result = session.sql(f\"\"\"\n        SELECT SNOWFLAKE.CORTEX.COMPLETE(\n            '{model}',\n            ARRAY_CONSTRUCT(OBJECT_CONSTRUCT('role', 'user', 'content', '{st.session_state.prompt.replace(\"'\", \"''\")}')),\n            OBJECT_CONSTRUCT('temperature', {options['temperature']}, 'max_tokens', {options['max_tokens']}, 'top_p', {options['top_p']})\n        ) AS response\n        \"\"\").collect()\n        \n        if result and len(result) > 0:\n            response_json = json.loads(result[0]['RESPONSE'])\n            st.session_state.ai_response = response_json\n        else:\n            st.error(\"No response received from the AI model.\")\n    except Exception as e:\n        st.error(f\"An error occurred: {str(e)}\")\n        st.session_state.ai_response = \"Error: Unable to get AI response.\"\n\nif st.button(\"Generate Prompt\"):\n    generate_prompt()\n    \n    # Calculate token count\n    try:\n        token_count_result = session.sql(f\"\"\"\n        SELECT SNOWFLAKE.CORTEX.COUNT_TOKENS(\n            '{model}',\n            '{st.session_state.prompt.replace(\"'\", \"''\")}'\n        ) AS token_count\n        \"\"\").collect()\n        \n        if token_count_result and len(token_count_result) > 0:\n            st.session_state.token_count = token_count_result[0]['TOKEN_COUNT']\n        else:\n            st.warning(\"Unable to calculate token count.\")\n    except Exception as e:\n        st.warning(f\"Error calculating token count: {str(e)}\")\n\nif st.session_state.prompt:\n    st.subheader(\"Generated Prompt:\")\n    st.text_area(\"Prompt\", st.session_state.prompt, height=300)\n    st.write(f\"Token Count: {st.session_state.token_count}\")\n    \n    st.subheader(\"Model Parameters\")\n    temperature = st.slider(\"Temperature\", 0.0, 1.0, 0.7, 0.1)\n    max_tokens = st.number_input(\"Max Tokens\", 1, 4096, min(st.session_state.token_count, 4096))\n    top_p = st.slider(\"Top P\", 0.0, 1.0, 1.0, 0.1)\n    \n    if st.button(\"Get AI Response\"):\n        options = {\n            \"temperature\": temperature,\n            \"max_tokens\": max_tokens,\n            \"top_p\": top_p,\n        }\n        get_ai_response(options)\n\nif st.session_state.ai_response:\n    st.subheader(\"AI Model Response:\")\n    if isinstance(st.session_state.ai_response, dict):\n        if 'choices' in st.session_state.ai_response and len(st.session_state.ai_response['choices']) > 0:\n            message = st.session_state.ai_response['choices'][0].get('messages', '')\n            st.markdown(message)\n        \n        if 'usage' in st.session_state.ai_response:\n            usage = st.session_state.ai_response['usage']\n            st.write(\"Token Usage:\")\n            st.write(f\"- Completion tokens: {usage.get('completion_tokens', 'N/A')}\")\n            st.write(f\"- Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\")\n            st.write(f\"- Total tokens: {usage.get('total_tokens', 'N/A')}\")\n        \n        if 'model' in st.session_state.ai_response:\n            st.write(f\"Model used: {st.session_state.ai_response['model']}\")\n    else:\n        st.write(st.session_state.ai_response)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5c1c8816-2723-43b1-a72f-4e3771fee06e",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "Sample Report Generated by Llama3.1-405b with Both Vector Embeddings and Smaple Data Given.\n\nAI Model Response:\nAfter analyzing the provided data, I've identified the following field mappings between the Modernised and Legacy tables:\n\nMatching Fields:\n\nACCOUNT_BALANCE (Modernised) → ACCT_BALANCE (Legacy)\nACCOUNT_NUMBER (Modernised) → ACCT_NUM (Legacy)\nACCOUNT_STATUS (Modernised) → ACCT_STATUS (Legacy)\nACCOUNT_TYPE (Modernised) → ACCT_TYPE (Legacy)\nADDRESS (Modernised) → ADDR (Legacy)\nBRANCH_ID (Modernised) → BRANCH_ID (Legacy)\nCITY (Modernised) → CITY (Legacy)\nCREATED_TIMESTAMP (Modernised) → CREATION_TIMESTAMP (Legacy)\nCUSTOMER_ID (Modernised) → CUST_ID (Legacy)\nDATE_OF_BIRTH (Modernised) → DOB (Legacy)\nEMAIL (Modernised) → EMAIL_ADDRESS (Legacy)\nFIRST_NAME (Modernised) → F_NAME (Legacy)\nINTEREST_RATE (Modernised) → INTEREST (Legacy)\nKYC_STATUS (Modernised) → KYC (Legacy)\nLAST_NAME (Modernised) → L_NAME (Legacy)\nLAST_TRANSACTION_DATE (Modernised) → LAST_TRANS_DATE (Legacy)\nMARKETING_OPT_IN (Modernised) → MARKETING_CONSENT (Legacy)\nPHONE_NUMBER (Modernised) → PHONE (Legacy)\nRISK_LEVEL (Modernised) → RISK (Legacy)\nSSN (Modernised) → SOCIAL_SECURITY_NUMBER (Legacy)\nSTATE (Modernised) → STATE (Legacy)\nZIP_CODE (Modernised) → POSTAL_CODE (Legacy)\nNon-Matching Fields:\n\nEMPLOYMENT_STATUS (Legacy) - No equivalent field in Modernised table.\nMIDDLE_NAME (Legacy) - No equivalent field in Modernised table.\nNATIONALITY (Legacy) - No equivalent field in Modernised table.\nMODIFICATION_TIMESTAMP (Legacy) - While there is an UPDATED_TIMESTAMP field in the Modernised table, the values do not match.\nOPEN_DATE (Legacy) - While there is a DATE_OPENED field in the Modernised table, the values do not match.\nTransformations:\n\nTo align the Modernised table with the Legacy table, the following transformations are necessary:\n\nRename ACCOUNT_BALANCE to ACCT_BALANCE\nRename ACCOUNT_NUMBER to ACCT_NUM\nRename ACCOUNT_STATUS to ACCT_STATUS\nRename ACCOUNT_TYPE to ACCT_TYPE\nRename ADDRESS to ADDR\nRename CREATED_TIMESTAMP to CREATION_TIMESTAMP\nRename CUSTOMER_ID to CUST_ID\nRename DATE_OF_BIRTH to DOB\nRename EMAIL to EMAIL_ADDRESS\nRename FIRST_NAME to F_NAME\nRename INTEREST_RATE to INTEREST\nRename KYC_STATUS to KYC\nRename LAST_NAME to L_NAME\nRename LAST_TRANSACTION_DATE to LAST_TRANS_DATE\nRename MARKETING_OPT_IN to MARKETING_CONSENT\nRename PHONE_NUMBER to PHONE\nRename RISK_LEVEL to RISK\nRename SSN to SOCIAL_SECURITY_NUMBER\nRename STATE to STATE (no change)\nRename ZIP_CODE to POSTAL_CODE\nHere is a sample Snowflake-compatible SQL query that performs these transformations:\n\nSELECT \n  ACCOUNT_BALANCE AS ACCT_BALANCE,\n  ACCOUNT_NUMBER AS ACCT_NUM,\n  ACCOUNT_STATUS AS ACCT_STATUS,\n  ACCOUNT_TYPE AS ACCT_TYPE,\n  ADDRESS AS ADDR,\n  BRANCH_ID,\n  CITY,\n  CREATED_TIMESTAMP AS CREATION_TIMESTAMP,\n  CUSTOMER_ID AS CUST_ID,\n  DATE_OF_BIRTH AS DOB,\n  EMAIL AS EMAIL_ADDRESS,\n  FIRST_NAME AS F_NAME,\n  INTEREST_RATE AS INTEREST,\n  KYC_STATUS AS KYC,\n  LAST_NAME AS L_NAME,\n  LAST_TRANSACTION_DATE AS LAST_TRANS_DATE,\n  MARKETING_OPT_IN AS MARKETING_CONSENT,\n  PHONE_NUMBER AS PHONE,\n  RISK_LEVEL AS RISK,\n  SSN AS SOCIAL_SECURITY_NUMBER,\n  STATE,\n  ZIP_CODE AS POSTAL_CODE\nFROM \n  MODERNISED_TABLE;\n\nNote that this query assumes that the Modernised table is named MODERNISED_TABLE. You should replace this with the actual table name in your database. Additionally, this query does not handle the non-matching fields (EMPLOYMENT_STATUS, MIDDLE_NAME, NATIONALITY, MODIFICATION_TIMESTAMP, and OPEN_DATE). You will need to decide how to handle these fields based on your specific use case.\n\nToken Usage:\n\nCompletion tokens: 1131\nPrompt tokens: 4173\nTotal tokens: 5304\nModel used: llama3.1-405b"
  },
  {
   "cell_type": "markdown",
   "id": "601180d7-e8e4-4ea6-bf44-0daa2d6836ab",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "Model Response for Different Dataset with Array type compared only with sample data .\n\nBased on the provided data, I've identified the following discrepancies and mapping between the Modernised and Legacy tables:\n\nField name mismatches:\nCREATED_AT (Modernised) vs. CRT_DT (Legacy)\nCUSTOMER_SINCE (Modernised) vs. CUST_SINCE (Legacy)\nDATE_OF_BIRTH (Modernised) vs. DOB (Legacy)\nANNUAL_INCOME (Modernised) vs. ANN_INC (Legacy)\nEDUCATION_LEVEL (Modernised) vs. EDU_LVL (Legacy)\nEMPLOYMENT_STATUS (Modernised) vs. EMP_STS (Legacy)\nGENDER (Modernised) vs. GNDR (Legacy)\nHOUSEHOLD_SIZE (Modernised) vs. HHLD_SZ (Legacy)\nHOME_OWNERSHIP (Modernised) vs. HOME_OWN (Legacy)\nLEGAL_NAME (Modernised) vs. LEGAL_NM (Legacy)\nMARITAL_STATUS (Modernised) vs. MRTL_STS (Legacy)\nNET_WORTH (Modernised) vs. NET_WRTH (Legacy)\nOCCUPATION (Modernised) vs. OCCPTN (Legacy)\nPARTY_TYPE (Modernised) vs. PARTY_TYP (Legacy)\nUPDATED_AT (Modernised) vs. UPD_DT (Legacy)\nData type mismatches:\nDEMOGRAPHICS (Modernised) is an array of objects, while the Legacy table has separate fields for each demographic attribute.\nData value mismatches:\nThe PARTY_ID values do not match between the two tables.\nTo transform the Modernised table to align with the Legacy table, I suggest the following Snowflake compatible SQL query:\n\nSELECT \n    m.PARTY_ID,\n    m.CREATED_AT AS CRT_DT,\n    m.CUSTOMER_SINCE AS CUST_SINCE,\n    m.DATE_OF_BIRTH AS DOB,\n    d.ANNUAL_INCOME AS ANN_INC,\n    d.EDUCATION_LEVEL AS EDU_LVL,\n    d.EMPLOYMENT_STATUS AS EMP_STS,\n    d.GENDER AS GNDR,\n    d.HOUSEHOLD_SIZE AS HHLD_SZ,\n    d.HOME_OWNERSHIP AS HOME_OWN,\n    m.LEGAL_NAME AS LEGAL_NM,\n    d.MARITAL_STATUS AS MRTL_STS,\n    d.NET_WORTH AS NET_WRTH,\n    d.OCCUPATION AS OCCPTN,\n    m.PARTY_TYPE AS PARTY_TYP,\n    m.UPDATED_AT AS UPD_DT\nFROM \n    modern_data.processed_data m,\n    LATERAL FLATTEN(m.DEMOGRAPHICS) d\n\nThis query flattens the DEMOGRAPHICS array and joins it with the main table, mapping the fields to their corresponding Legacy table fields.\n\nNote that the PARTY_ID values still do not match between the two tables. To resolve this, you may need to perform additional data cleansing or matching steps.\n\nAdditionally, the Legacy table has separate fields for each demographic attribute, while the Modernised table has an array of objects. If you want to maintain the same data structure in the transformed table, you can modify the query to use Snowflake's OBJECT_CONSTRUCT function to create separate columns for each demographic attribute. For example:\n\nSELECT \n    m.PARTY_ID,\n    m.CREATED_AT AS CRT_DT,\n    m.CUSTOMER_SINCE AS CUST_SINCE,\n    m.DATE_OF_BIRTH AS DOB,\n    OBJECT_CONSTRUCT(\n        'ANN_INC': d.ANNUAL_INCOME,\n        'EDU_LVL': d.EDUCATION_LEVEL,\n        'EMP_STS': d.EMPLOYMENT_STATUS,\n        'GNDR': d.GENDER,\n        'HHLD_SZ': d.HOUSEHOLD_SIZE,\n        'HOME_OWN': d.HOME_OWNERSHIP,\n        'MRTL_STS': d.MARITAL_STATUS,\n        'NET_WRTH': d.NET_WORTH,\n        'OCCPTN': d.OCCUPATION\n    ) AS DEMOGRAPHICS,\n    m.LEGAL_NAME AS LEGAL_NM,\n    m.PARTY_TYPE AS PARTY_TYP,\n    m.UPDATED_AT AS UPD_DT\nFROM \n    modern_data.processed_data m,\n    LATERAL FLATTEN(m.DEMOGRAPHICS) d\n\nThis will create a DEMOGRAPHICS column with a JSON object containing the individual demographic attributes.\n\nToken Usage:\n\nCompletion tokens: 1012\nPrompt tokens: 896\nTotal tokens: 1908\nModel used: llama3.1-405b"
  }
 ]
}