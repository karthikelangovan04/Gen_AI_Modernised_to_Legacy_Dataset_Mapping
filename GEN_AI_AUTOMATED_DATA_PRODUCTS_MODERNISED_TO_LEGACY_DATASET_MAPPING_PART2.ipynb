{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b99590-436b-4f2e-9c3c-c99fb48b4bac",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "# Explanation:\n# 1. This function is named PROCESS_TABLE_DATA and takes one parameter named \"DATA\"\n# 2. The input and output are both VARCHAR with a maximum length of 16,777,216 characters\n# 3. The function is written in Python, using version 3.8\n# 4. The entry point of the function is a Python function named \"process_data\"\n# 5. The function body is enclosed in single quotes and contains Python code\n# 6. The function parses input JSON, could perform processing (currently just passes data through),\n#    and returns the result as a JSON string\nThis code creates a User-Defined Function (UDF) in Snowflake that can process JSON data. The function takes a JSON string as input, parses it, and returns a new JSON string. Currently, it doesn't perform any actual processing - it just wraps the input data in a new JSON object with a \"processed_data\" key. In a real-world scenario, you would typically add some data transformation or analysis logic in the process_data function."
  },
  {
   "cell_type": "code",
   "id": "90e17b1d-52d2-40ad-a13b-04b595094050",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FUNCTION PROCESS_TABLE_DATA(\"DATA\" VARCHAR(16777216))\nRETURNS VARCHAR(16777216)\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.8'\nHANDLER = 'process_data'\nAS '\nimport json\n\ndef process_data(data: str) -> str:\n    # Parse JSON data\n    rows = json.loads(data)\n    \n    # Example processing: Just return the data received\n    result = {\"processed_data\": rows}\n    \n    return json.dumps(result)\n';",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ebc3ac2b-cda7-47bc-9eda-dcc9b9b84034",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "-- This SQL statement creates or replaces a stored procedure in Snowflake\n\n-- Procedure name: FETCH_AND_PROCESS_TABLE_DATA\n-- Input parameters:\n--   DATABASE_NAME: Name of the database (VARCHAR)\n--   SCHEMA_NAME: Name of the schema (VARCHAR)\n--   TABLE_NAME: Name of the table (VARCHAR)\n--   RECORD_LIMIT: Number of records to fetch (NUMBER)\n-- Returns: VARIANT (a semi-structured data type that can hold any valid JSON)\n-- Language: SQL\n-- Execution context: OWNER (runs with the privileges of the procedure owner)\n\n-- Declare variables:\n--   sql_query: Stores the dynamically constructed SQL query\n--   result_id: Stores the query ID of the executed dynamic SQL\n--   json_result: Stores the fetched data as a JSON string\n--   processed_result: Stores the result after processing the JSON data\n\n-- Construct a dynamic SQL query:\n-- This query selects all columns from the specified table,\n-- applies the RECORD_LIMIT, and aggregates the results into a JSON array\n\n-- Execute the dynamic SQL query\n\n-- Get the ID of the last executed query\n\n-- Use RESULT_SCAN to fetch the results of the dynamic query\n-- Convert the results to a JSON string\n\n-- Process the JSON data using the PROCESS_TABLE_DATA UDF\n-- This UDF is assumed to be previously defined\n\n-- Parse the processed result back into a VARIANT type and return it\n\n-- End of the procedure"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "cell1",
    "collapsed": false
   },
   "source": "CREATE OR REPLACE PROCEDURE FETCH_AND_PROCESS_TABLE_DATA(\"DATABASE_NAME\" VARCHAR(16777216), \"SCHEMA_NAME\" VARCHAR(16777216), \"TABLE_NAME\" VARCHAR(16777216), \"RECORD_LIMIT\" NUMBER(38,0))\nRETURNS VARIANT\nLANGUAGE SQL\nEXECUTE AS OWNER\nAS '\nDECLARE\n    sql_query STRING;\n    result_id STRING;\n    json_result STRING;\n    processed_result STRING;\nBEGIN\n    -- Construct the dynamic SQL query to fetch data with LIMIT applied in the subquery\n    sql_query := ''SELECT ARRAY_AGG(OBJECT_CONSTRUCT(*)) AS json_data FROM (\n                    SELECT * FROM '' || database_name || ''.'' || schema_name || ''.'' || table_name || \n                    '' LIMIT '' || record_limit || \n                  '')'';\n    \n    -- Execute the dynamic SQL query\n    EXECUTE IMMEDIATE :sql_query;\n    \n    -- Get the last query ID\n    result_id := LAST_QUERY_ID();\n    \n    -- Use RESULT_SCAN to fetch the results and store as a STRING\n    SELECT TO_JSON(json_data)::STRING INTO :json_result FROM TABLE(RESULT_SCAN(:result_id));\n    \n    -- Process the JSON data using the Python UDF\n    processed_result := PROCESS_TABLE_DATA(:json_result);\n    \n    -- Return the processed result as a VARIANT\n    RETURN PARSE_JSON(:processed_result);\nEND;\n';\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4deba5e8-aac5-4155-8e39-653ac2e4fc13",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "--SMART_AI_MAPPER.SMART_AI_MAPPER_TOOL.DEPOSIT_ACCOUNTS_MODERNISED\n--SMART_AI_MAPPER.SMART_AI_MAPPER_TOOL.DEPOSIT_ACCOUNTS_LEGACY\ncall fetch_and_process_table_data('SMART_AI_MAPPER', 'SMART_AI_MAPPER_TOOL', 'DEPOSIT_ACCOUNTS_MODERNISED', 2);",
   "execution_count": null
  }
 ]
}
